{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Este notebook es encargado de generar un CSV que consolide todas las pruebas y estandarice los valores de cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"..//resources//csv//data//sujeto1-rocio-2020-10-25-biometrics.csv\")\n",
    "df_2 = pd.read_csv(\"..//resources//csv//data//sujeto2-juan-2020-11-01-biometrics.csv\")\n",
    "df_3 = pd.read_csv(\"..//resources//csv//data//sujeto3-brenda-2020-11-16-biometrics.csv\")\n",
    "df_4 = pd.read_csv(\"..//resources//csv//data//sujeto4-matias-2020-11-16-biometrics.csv\")\n",
    "df_5 = pd.read_csv(\"..//resources//csv//data//sujeto5-sebastian-2021-01-05-biometrics.csv\")\n",
    "df_6 = pd.read_csv(\"..//resources//csv//data//sujeto6-rocio-2021-01-07-biometrics.csv\")\n",
    "# df_7 = pd.read_csv(\"..//resources//csv//data//sujeto7-seb-2021-03-24-biometrics.csv\")\n",
    "# df_8 = pd.read_csv(\"..//resources//csv//data//sujeto8-bren-2021-04-04-biometrics.csv\")\n",
    "\n",
    "dfs = [df_1, df_2, df_3, df_5, df_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prev_values(df, col):\n",
    "    df.loc[0, f'{col}-4'] = df.loc[0, col]\n",
    "    df.loc[0, f'{col}-3'] = df.loc[0, col]\n",
    "    df.loc[0, f'{col}-2'] = df.loc[0, col]\n",
    "    df.loc[0, f'{col}-1'] = df.loc[0, col]\n",
    "\n",
    "    for i in range(0, len(df)):\n",
    "        if i >= 4:\n",
    "            df.loc[i, f'{col}-4'] = df.loc[i-4, col]\n",
    "            df.loc[i, f'{col}-3'] = df.loc[i-3, col]\n",
    "            df.loc[i, f'{col}-2'] = df.loc[i-2, col]\n",
    "            df.loc[i, f'{col}-1'] = df.loc[i-1, col]\n",
    "        else:\n",
    "            df.loc[i, f'{col}-4'] = df.loc[i, col]\n",
    "            df.loc[i, f'{col}-3'] = df.loc[i, col]\n",
    "            df.loc[i, f'{col}-2'] = df.loc[i, col]\n",
    "            df.loc[i, f'{col}-1'] = df.loc[i, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que determina cuando un sujeto se encuentra en un estado de excitación (1) o relajación (0) dado un valor de arousal.\n",
    "def isAroused(arousal):\n",
    "    return 0 if arousal < 5 else 1\n",
    "\n",
    "# Función que estandariza las columas dadas de un dataframe\n",
    "def standarize(df):\n",
    "    df_to_standarize = df.copy()\n",
    "    \n",
    "    # Se remueven las mediciones sin estímulo (previas al inicio de estímulos), para no ofuscar el entrenamiento\n",
    "    filterNoArousalMeasurements = df_to_standarize['ArousalMean'] > 0\n",
    "    df_to_standarize = df_to_standarize[filterNoArousalMeasurements]\n",
    "\n",
    "    # remover las mediciones para las que el sam no coincidió antes de la estandarización, para no afectar la desviación\n",
    "    # filterNoMatchesSAMMeasurements = filtered1['MatchesSam'] == True\n",
    "    # df_to_standarize = df_to_standarize[filterNoMatchesSAMMeasurements]\n",
    "    \n",
    "    # Se agrega la columna Aroused (0/1) para la clasificación binaria\n",
    "    df_to_standarize['Aroused'] = df_to_standarize['ArousalMean'].map(isAroused)\n",
    "    \n",
    "    columns_to_standarize = ['HR', 'RR', 'HRV', 'MicroSiemens']\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "#     scaler = preprocessing.MinMaxScaler()\n",
    "    standarized_df = scaler.fit_transform(df_to_standarize[columns_to_standarize])\n",
    "\n",
    "    standarized_df_with_rest_of_data = np.append(standarized_df, df_to_standarize[['SCR', 'SCR_MIN', 'PhaseName', 'ArousalMean', 'Aroused', 'TimeStamp']], axis=1)\n",
    "    \n",
    "    # Se convierte a DataFrame\n",
    "    standarized_df_with_rest_of_data = pd.DataFrame(standarized_df_with_rest_of_data, columns=['HR', 'RR', 'HRV', 'MicroSiemens', 'SCR', 'SCR_MIN', 'PhaseName', 'ArousalMean', 'Aroused', 'TimeStamp'])\n",
    "    \n",
    "    # Conversión de tipos\n",
    "    standarized_df_with_rest_of_data['HR'] = standarized_df_with_rest_of_data['HR'].astype(float)\n",
    "    standarized_df_with_rest_of_data['RR'] = standarized_df_with_rest_of_data['RR'].astype(float)\n",
    "    standarized_df_with_rest_of_data['HRV'] = standarized_df_with_rest_of_data['HRV'].astype(float)\n",
    "    standarized_df_with_rest_of_data['MicroSiemens'] = standarized_df_with_rest_of_data['MicroSiemens'].astype(float)\n",
    "    standarized_df_with_rest_of_data['SCR'] = standarized_df_with_rest_of_data['SCR'].astype(int)\n",
    "    standarized_df_with_rest_of_data['SCR_MIN'] = standarized_df_with_rest_of_data['SCR_MIN'].astype(int)\n",
    "    standarized_df_with_rest_of_data['PhaseName'] = standarized_df_with_rest_of_data['PhaseName']\n",
    "    standarized_df_with_rest_of_data['ArousalMean'] = standarized_df_with_rest_of_data['ArousalMean'].astype(float)\n",
    "    standarized_df_with_rest_of_data['Aroused'] = standarized_df_with_rest_of_data['Aroused'].astype(int)\n",
    "    standarized_df_with_rest_of_data['TimeStamp'] = standarized_df_with_rest_of_data['TimeStamp']\n",
    "    \n",
    "\n",
    "    add_prev_values(standarized_df_with_rest_of_data, \"HR\")\n",
    "    add_prev_values(standarized_df_with_rest_of_data, \"HRV\")\n",
    "    add_prev_values(standarized_df_with_rest_of_data, \"MicroSiemens\")\n",
    "\n",
    "    return standarized_df_with_rest_of_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se estandariza cada dataframe\n",
    "standarized_dfs = list(map(standarize, dfs))\n",
    "\n",
    "# Se los une a todos en un solo dataframe para entrenamiento luego de la estandarización\n",
    "biometrics_df = pd.concat(standarized_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.gonzalez/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "biometrics_df.to_csv(r'./1_standarized_biometrics.csv', index = False)\n",
    "# When you want to see the grphs comment the exit line\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_explore = biometrics_df # todos los sujetos consolidados\n",
    "# df_to_explore = standarized_dfs[0] # Sujeto 1\n",
    "# df_to_explore = standarized_dfs[1] # Sujeto 2\n",
    "# df_to_explore = standarized_dfs[2] # Sujeto 3\n",
    "# df_to_explore = standarized_dfs[3] # Sujeto 4\n",
    "# df_to_explore = standarized_dfs[4] # Sujeto 5\n",
    "# df_to_explore = standarized_dfs[5] # Sujeto 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_explore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_explore.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_explore.groupby('Aroused').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_explore.hist(edgecolor='black', linewidth=1.2, figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8));\n",
    "plt.subplot(2,3,1)\n",
    "sns.violinplot(x='Aroused', y='HR', data=df_to_explore)\n",
    "plt.subplot(2,3,2)\n",
    "sns.violinplot(x='Aroused', y='HRV', data=df_to_explore)\n",
    "plt.subplot(2,3,3)\n",
    "sns.violinplot(x='Aroused', y='MicroSiemens', data=df_to_explore)\n",
    "plt.subplot(2,3,4)\n",
    "sns.violinplot(x='Aroused', y='SCR_MIN', data=df_to_explore);\n",
    "plt.subplot(2,3,5)\n",
    "sns.violinplot(x='Aroused', y='SCR', data=df_to_explore);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "# filtered = biometrics_df[cols]\n",
    "mask = np.triu(np.ones_like(df_to_explore.corr(), dtype=np.bool))\n",
    "heatmap = sns.heatmap(df_to_explore.corr(), annot=True, mask=mask, fmt=\".2f\", cmap='YlGnBu')\n",
    "heatmap.set_title('Mapa de calor de coorrelación', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterPhaseName = df_to_explore['PhaseName'] == \"HA_NV_16\"\n",
    "df_to_pairplot = df_to_explore[filterPhaseName]\n",
    "\n",
    "# Ignore filter\n",
    "# df_to_pairplot = df_to_explore\n",
    "\n",
    "sns.pairplot(df_to_pairplot, palette='Paired', hue='PhaseName', corner=True, diag_kind=\"hist\", plot_kws=dict(marker=\"+\", linewidth=1))\n",
    "# for df in standarized_dfs:\n",
    "#     sns.pairplot(df, vars=cols, palette='Paired', hue='PhaseName', corner=True, diag_kind=\"hist\", plot_kws=dict(marker=\"+\", linewidth=1))\n",
    "#     sns.pairplot(df, vars=cols, palette='Paired', hue='Aroused', hue_order=[1, 0], corner=True, diag_kind=\"hist\", plot_kws=dict(marker=\"+\", linewidth=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
