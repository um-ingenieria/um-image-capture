{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Este notebook es encargado utilizar el CSV con las prruebas consolidadas para crear y entrenar un modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>RR</th>\n",
       "      <th>HRV</th>\n",
       "      <th>MicroSiemens</th>\n",
       "      <th>SCR</th>\n",
       "      <th>SCR_MIN</th>\n",
       "      <th>PhaseName</th>\n",
       "      <th>ArousalMean</th>\n",
       "      <th>Aroused</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.180957</td>\n",
       "      <td>-0.246737</td>\n",
       "      <td>-0.638383</td>\n",
       "      <td>1.604263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HA_PV</td>\n",
       "      <td>6.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.463350</td>\n",
       "      <td>-0.508771</td>\n",
       "      <td>-0.930989</td>\n",
       "      <td>1.357679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HA_PV</td>\n",
       "      <td>6.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.419905</td>\n",
       "      <td>-0.468458</td>\n",
       "      <td>-1.085573</td>\n",
       "      <td>1.357679</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HA_PV</td>\n",
       "      <td>6.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.419905</td>\n",
       "      <td>-0.468458</td>\n",
       "      <td>-1.121459</td>\n",
       "      <td>1.111095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HA_PV</td>\n",
       "      <td>7.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.506795</td>\n",
       "      <td>-0.549084</td>\n",
       "      <td>-1.088333</td>\n",
       "      <td>1.111095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HA_PV</td>\n",
       "      <td>7.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HR        RR       HRV  MicroSiemens  SCR  SCR_MIN PhaseName  \\\n",
       "0  0.180957 -0.246737 -0.638383      1.604263    0        0     HA_PV   \n",
       "1  0.463350 -0.508771 -0.930989      1.357679    0        0     HA_PV   \n",
       "2  0.419905 -0.468458 -1.085573      1.357679    0        0     HA_PV   \n",
       "3  0.419905 -0.468458 -1.121459      1.111095    0        0     HA_PV   \n",
       "4  0.506795 -0.549084 -1.088333      1.111095    0        0     HA_PV   \n",
       "\n",
       "   ArousalMean  Aroused  \n",
       "0         6.07        1  \n",
       "1         6.07        1  \n",
       "2         6.07        1  \n",
       "3         7.31        1  \n",
       "4         7.31        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biometrics_df = pd.read_csv(\"./1_standarized_biometrics.csv\")\n",
    "biometrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = biometrics_df[['MicroSiemens', 'HR', 'HRV' ]].values\n",
    "y = biometrics_df['Aroused'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.60426292,  0.18095678, -0.63838286],\n",
       "       [ 1.35767905,  0.46335022, -0.93098869],\n",
       "       [ 1.35767905,  0.41990507, -1.08557291],\n",
       "       ...,\n",
       "       [ 0.92410292, -1.00764835, -1.10377383],\n",
       "       [ 1.11904139, -0.46657089, -1.00562414],\n",
       "       [ 1.21651063,  0.73582348, -0.90011322]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Para poder usar un clasificador, los datos de la variable target deben ser discretos.\n",
    "# #Los convertimos a True-False (Aroused-NotAroused) con el fin de poder entrear un clasificador binario\n",
    "# def map_to_0_and_1(arousal):\n",
    "#     return 0 if arousal < 5 else 1\n",
    "\n",
    "# y_train = np.array(list(map(map_to_0_and_1, y_train)))\n",
    "# y_test = np.array(list(map(map_to_0_and_1, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"adaboost\"\n",
    "model = \"knn\"\n",
    "# model = \"random-forest\"\n",
    "# model = \"svm-rbf\"\n",
    "# model = \"svm-poly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == \"adaboost\":\n",
    "    clf = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "    #Adaboost with RandomForest\n",
    "    clf2 = AdaBoostClassifier(RandomForestClassifier(n_estimators=100), n_estimators=100)\n",
    "    print(f\"Usando {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando knn\n"
     ]
    }
   ],
   "source": [
    "if model == \"knn\":\n",
    "    clf = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "\n",
    "    # Grid Search\n",
    "    clf.get_params()\n",
    "    params = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "    grid_search_cv = GridSearchCV(KNeighborsClassifier(), params, n_jobs=-1, verbose=1)\n",
    "    print(f\"Usando {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == \"random-forest\":\n",
    "    clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "    # Grid Search\n",
    "    rf_clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    params_grid = {\"max_depth\": [3, None], \"min_samples_split\": [2, 3, 10], \"min_samples_leaf\": [1, 3, 10], \"bootstrap\": [True, False], \"criterion\": ['gini', 'entropy']}\n",
    "    grid_search_cv = GridSearchCV(rf_clf, params_grid, n_jobs=-1, cv=5, verbose=1, scoring='accuracy', iid=False)\n",
    "    print(f\"Usando {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == \"svm-rbf\":\n",
    "    clf = svm.SVC(C=0.1, gamma=0.01, kernel='rbf')\n",
    "    \n",
    "    # Grid Search\n",
    "    pipeline = Pipeline([('clf', svm.SVC(kernel='rbf', C=1, gamma=0.1))])\n",
    "    params = {'clf__C':(0.1, 0.5, 1, 2, 5, 10, 20), 'clf__gamma':(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1)}\n",
    "    grid_search_cv = GridSearchCV(pipeline, params, n_jobs=-1, cv=3, verbose=1, scoring='accuracy')\n",
    "    print(f\"Usando {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == \"svm-poly\":\n",
    "    clf = svm.SVC(kernel='poly', degree=3)\n",
    "    \n",
    "    # Grid Search\n",
    "    pipeline = Pipeline([('clf', svm.SVC(kernel='poly'))])\n",
    "    params = {'clf__C':(0.1, 0.5, 1, 2, 5, 10, 20), 'clf__gamma':(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), 'clf__degree': (3, 4, 5)}\n",
    "    grid_search_cv = GridSearchCV(pipeline, params, n_jobs=-1, cv=3, verbose=1, scoring='accuracy')\n",
    "    print(f\"Usando {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        print(\"Train Result:\\n\")\n",
    "        print(\"Accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, clf.predict(X_train))))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, clf.predict(X_train))))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, clf.predict(X_train))))\n",
    "\n",
    "        res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        print(\"Cross Validation \\t\")\n",
    "        print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n",
    "        print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n",
    "        \n",
    "    elif train==False:\n",
    "        print(\"Test Result:\\n\")        \n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, clf.predict(X_test))))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, clf.predict(X_test))))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, clf.predict(X_test))))        \n",
    "        \n",
    "        res = cross_val_score(clf, X_test, y_test, cv=10, scoring='accuracy')\n",
    "        print(\"Cross Validation \\t\")\n",
    "        print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n",
    "        print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "\n",
      "Accuracy score: 0.8106\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76       851\n",
      "           1       0.82      0.86      0.84      1198\n",
      "\n",
      "    accuracy                           0.81      2049\n",
      "   macro avg       0.81      0.80      0.80      2049\n",
      "weighted avg       0.81      0.81      0.81      2049\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 626  225]\n",
      " [ 163 1035]]\n",
      "\n",
      "Cross Validation \t\n",
      "Average Accuracy: \t 0.5993\n",
      "Accuracy SD: \t\t 0.0591\n",
      "\n",
      "******************************\n",
      "\n",
      "Test Result:\n",
      "\n",
      "accuracy score: 0.6043\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52       225\n",
      "           1       0.64      0.69      0.66       288\n",
      "\n",
      "    accuracy                           0.60       513\n",
      "   macro avg       0.60      0.59      0.59       513\n",
      "weighted avg       0.60      0.60      0.60       513\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[111 114]\n",
      " [ 89 199]]\n",
      "\n",
      "Cross Validation \t\n",
      "Average Accuracy: \t 0.6468\n",
      "Accuracy SD: \t\t 0.1750\n"
     ]
    }
   ],
   "source": [
    "print_score(clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print(\"\\n******************************\\n\")\n",
    "print_score(clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "\n",
      "Accuracy score: 0.7804\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       851\n",
      "           1       0.79      0.85      0.82      1198\n",
      "\n",
      "    accuracy                           0.78      2049\n",
      "   macro avg       0.78      0.77      0.77      2049\n",
      "weighted avg       0.78      0.78      0.78      2049\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 577  274]\n",
      " [ 176 1022]]\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Cross Validation \t\n",
      "Average Accuracy: \t 0.6047\n",
      "Accuracy SD: \t\t 0.0602\n",
      "\n",
      "******************************\n",
      "\n",
      "Test Result:\n",
      "\n",
      "accuracy score: 0.6238\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.49      0.53       225\n",
      "           1       0.65      0.73      0.69       288\n",
      "\n",
      "    accuracy                           0.62       513\n",
      "   macro avg       0.62      0.61      0.61       513\n",
      "weighted avg       0.62      0.62      0.62       513\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[110 115]\n",
      " [ 78 210]]\n",
      "\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  50 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Cross Validation \t\n",
      "Average Accuracy: \t 0.6176\n",
      "Accuracy SD: \t\t 0.1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00259438, 0.00253739, 0.0014595 , 0.00130663, 0.0015728 ,\n",
       "        0.00210962, 0.00136185, 0.0013062 , 0.00123167, 0.00115724]),\n",
       " 'std_fit_time': array([9.44393232e-04, 1.64960322e-03, 1.48358255e-04, 5.87937702e-05,\n",
       "        5.27371946e-04, 1.53238510e-03, 1.11255316e-04, 4.35275805e-05,\n",
       "        5.82532267e-05, 3.23140830e-05]),\n",
       " 'mean_score_time': array([0.02506371, 0.02823439, 0.02901006, 0.03039026, 0.02951145,\n",
       "        0.02755704, 0.02669172, 0.02630658, 0.02354898, 0.0186584 ]),\n",
       " 'std_score_time': array([0.00324173, 0.00157902, 0.00313853, 0.00172368, 0.00185849,\n",
       "        0.00192348, 0.00150971, 0.00111407, 0.00111386, 0.00338236]),\n",
       " 'param_n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 1},\n",
       "  {'n_neighbors': 2},\n",
       "  {'n_neighbors': 3},\n",
       "  {'n_neighbors': 4},\n",
       "  {'n_neighbors': 5},\n",
       "  {'n_neighbors': 6},\n",
       "  {'n_neighbors': 7},\n",
       "  {'n_neighbors': 8},\n",
       "  {'n_neighbors': 9},\n",
       "  {'n_neighbors': 10}],\n",
       " 'split0_test_score': array([0.56585366, 0.52195122, 0.58780488, 0.53902439, 0.55609756,\n",
       "        0.53414634, 0.55365854, 0.55853659, 0.56829268, 0.57073171]),\n",
       " 'split1_test_score': array([0.58780488, 0.56585366, 0.60731707, 0.57317073, 0.60731707,\n",
       "        0.59268293, 0.61219512, 0.5902439 , 0.59756098, 0.57073171]),\n",
       " 'split2_test_score': array([0.57804878, 0.56097561, 0.6097561 , 0.59512195, 0.62439024,\n",
       "        0.6195122 , 0.64634146, 0.62926829, 0.65365854, 0.63414634]),\n",
       " 'split3_test_score': array([0.55609756, 0.51463415, 0.5195122 , 0.50731707, 0.51707317,\n",
       "        0.5195122 , 0.53902439, 0.51707317, 0.56341463, 0.52682927]),\n",
       " 'split4_test_score': array([0.60880196, 0.60635697, 0.6601467 , 0.67481663, 0.67237164,\n",
       "        0.68459658, 0.67237164, 0.69193154, 0.68704156, 0.70171149]),\n",
       " 'mean_test_score': array([0.57932137, 0.55395432, 0.59690739, 0.57789015, 0.59544994,\n",
       "        0.59009005, 0.60471823, 0.5974107 , 0.61399368, 0.6008301 ]),\n",
       " 'std_test_score': array([0.01823962, 0.03318796, 0.04548743, 0.05692988, 0.05401268,\n",
       "        0.05985783, 0.05155221, 0.05994293, 0.04863363, 0.06095076]),\n",
       " 'rank_test_score': array([ 8, 10,  5,  9,  6,  7,  2,  4,  1,  3], dtype=int32)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_grid = grid_search_cv.predict(X_test)\n",
    "\n",
    "print_score(grid_search_cv, X_train, y_train, X_test, y_test, train=True)\n",
    "print(\"\\n******************************\\n\")\n",
    "print_score(grid_search_cv, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "grid_search_cv.best_estimator_\n",
    "grid_search_cv.best_estimator_.get_params()\n",
    "grid_search_cv.best_params_\n",
    "grid_search_cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "pickle.dump(grid_search_cv, open('./models/model', 'wb'))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
