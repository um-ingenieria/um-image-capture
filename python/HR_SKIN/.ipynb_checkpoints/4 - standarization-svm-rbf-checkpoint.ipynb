{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>HRV</th>\n",
       "      <th>MicroSiemens</th>\n",
       "      <th>ArousalMean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.255155</td>\n",
       "      <td>-1.609745</td>\n",
       "      <td>-1.658083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.427759</td>\n",
       "      <td>-1.627232</td>\n",
       "      <td>-1.646859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.088221</td>\n",
       "      <td>-1.627232</td>\n",
       "      <td>-1.658083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.133748</td>\n",
       "      <td>-1.627232</td>\n",
       "      <td>-1.658083</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.224803</td>\n",
       "      <td>-1.443622</td>\n",
       "      <td>-1.669307</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HR       HRV  MicroSiemens  ArousalMean\n",
       "0 -0.255155 -1.609745     -1.658083          0.0\n",
       "1  0.427759 -1.627232     -1.646859          0.0\n",
       "2 -0.088221 -1.627232     -1.658083          0.0\n",
       "3 -0.133748 -1.627232     -1.658083          0.0\n",
       "4 -0.224803 -1.443622     -1.669307          0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biometrics_df = pd.read_csv(\"../1_standarized_biometrics.csv\")\n",
    "biometrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, X_test, y_train, y_test, train=True):\n",
    "    '''\n",
    "    v0.1 Follow the scikit learn library format in terms of input\n",
    "    print the accuracy score, classification report and confusion matrix of classifier\n",
    "    '''\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_train)\n",
    "    if train:\n",
    "        '''\n",
    "        training performance\n",
    "        '''\n",
    "        res = clf.predict(X_train)\n",
    "        print(\"Train Result:\\n\")\n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_train, \n",
    "                                                                res)))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_train, \n",
    "                                                                            res)))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_train, \n",
    "                                                                  res)))\n",
    "        \n",
    "        res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        print(\"Average Accuracy: \\t {0:.4f}\".format(np.mean(res)))\n",
    "        print(\"Accuracy SD: \\t\\t {0:.4f}\".format(np.std(res)))\n",
    "        \n",
    "    elif train==False:\n",
    "        '''\n",
    "        test performance\n",
    "        '''\n",
    "        res_test = clf.predict(X_test)\n",
    "        print(\"Test Result:\\n\")        \n",
    "        print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, \n",
    "                                                                res_test)))\n",
    "        print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, \n",
    "                                                                            res_test)))\n",
    "        print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, \n",
    "                                                                  res_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = biometrics_df[['MicroSiemens', 'HR', 'HRV' ]].values\n",
    "y = biometrics_df['ArousalMean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para poder usar un clasificador, los datos de la variable target deben ser discretos.\n",
    "#Los convertimos a True-False (Aroused-NotAroused) con el fin de poder entrear un clasificador binario\n",
    "def map_to_0_and_1(arousal):\n",
    "    return 0 if arousal < 5 else 1\n",
    "\n",
    "y_train_aroused = np.array(list(map(map_to_0_and_1, y_train)))\n",
    "y_test_aroused = np.array(list(map(map_to_0_and_1, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, gamma=0.01)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = svm.SVC(C=0.1, gamma=0.01, kernel='rbf') los valores que dio el grid search\n",
    "clf = svm.SVC(C=0.1, gamma=0.01, kernel='rbf')\n",
    "clf.fit(X_train, y_train_aroused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "\n",
      "accuracy score: 0.7036\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.83      2155\n",
      "           1       0.00      0.00      0.00       908\n",
      "\n",
      "    accuracy                           0.70      3063\n",
      "   macro avg       0.35      0.50      0.41      3063\n",
      "weighted avg       0.49      0.70      0.58      3063\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2155    0]\n",
      " [ 908    0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.gonzalez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: \t 0.7036\n",
      "Accuracy SD: \t\t 0.0012\n",
      "\n",
      "******************************\n",
      "\n",
      "Test Result:\n",
      "\n",
      "accuracy score: 0.4948\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66       379\n",
      "           1       0.00      0.00      0.00       387\n",
      "\n",
      "    accuracy                           0.49       766\n",
      "   macro avg       0.25      0.50      0.33       766\n",
      "weighted avg       0.24      0.49      0.33       766\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[379   0]\n",
      " [387   0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.gonzalez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_score(clf, X_train, X_test, y_train_aroused, y_test_aroused, train=True)\n",
    "print(\"\\n******************************\\n\")\n",
    "print_score(clf, X_train, X_test, y_train_aroused, y_test_aroused, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN cross validation\n",
    "# y_train_pred = cross_val_predict(clf, X_train, y_train_aroused, cv=3)\n",
    "# pd.DataFrame(confusion_matrix(y_train_aroused, y_train_pred),\n",
    "#              columns=pd.MultiIndex.from_product([['Prediction'], [\"Negative\", \"Positive\"]]),\n",
    "#              index=pd.MultiIndex.from_product([[\"Actual\"], [\"Negative\", \"Positive\"]]))\n",
    "\n",
    "# TEST cross validation\n",
    "# y_test_pred = cross_val_predict(clf, X_test, y_test_aroused, cv=3)\n",
    "# pd.DataFrame(confusion_matrix(y_test_aroused, y_test_pred),\n",
    "#              columns=pd.MultiIndex.from_product([['Prediction'], [\"Negative\", \"Positive\"]]),\n",
    "#              index=pd.MultiIndex.from_product([[\"Actual\"], [\"Negative\", \"Positive\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('clf', svm.SVC(kernel='rbf', C=1, gamma=0.1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'clf__C':(0.1, 0.5, 1, 2, 5, 10, 20), 'clf__gamma':(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid_rbf = GridSearchCV(pipeline, params, n_jobs=-1, cv=3, verbose=1, scoring='accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('clf', SVC(C=1, gamma=0.1))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__C': (0.1, 0.5, 1, 2, 5, 10, 20),\n",
       "                         'clf__gamma': (0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1)},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid_rbf.fit(X_train, y_train_aroused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703558602677114"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid_rbf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = svm_grid_rbf.best_estimator_.get_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__C: \t 0.10\n",
      "\tclf__gamma: \t 0.00\n"
     ]
    }
   ],
   "source": [
    "for k in sorted(params.keys()): \n",
    "    print('\\t{0}: \\t {1:.2f}'.format(k, best[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred_grid = svm_grid_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "\n",
      "accuracy score: 0.7036\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.83      2155\n",
      "           1       0.00      0.00      0.00       908\n",
      "\n",
      "    accuracy                           0.70      3063\n",
      "   macro avg       0.35      0.50      0.41      3063\n",
      "weighted avg       0.49      0.70      0.58      3063\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[2155    0]\n",
      " [ 908    0]]\n",
      "\n",
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s.gonzalez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 124 out of 147 | elapsed:    1.9s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: \t 0.7036\n",
      "Accuracy SD: \t\t 0.0012\n",
      "\n",
      "******************************\n",
      "\n",
      "Test Result:\n",
      "\n",
      "accuracy score: 0.4948\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66       379\n",
      "           1       0.00      0.00      0.00       387\n",
      "\n",
      "    accuracy                           0.49       766\n",
      "   macro avg       0.25      0.50      0.33       766\n",
      "weighted avg       0.24      0.49      0.33       766\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[379   0]\n",
      " [387   0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:    2.2s finished\n",
      "/Users/s.gonzalez/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print_score(svm_grid_rbf, X_train, X_test, y_train_aroused, y_test_aroused, train=True)\n",
    "print(\"\\n******************************\\n\")\n",
    "print_score(svm_grid_rbf, X_train, X_test, y_train_aroused, y_test_aroused, train=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
